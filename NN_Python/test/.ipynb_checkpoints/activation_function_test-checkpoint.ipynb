{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook to test custom activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.models\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import csv\n",
    "from src.functions import initializers as ci # i.e., custom initializers\n",
    "from src.functions.layers import ActivLin1D\n",
    "from src.functions import activation_parameters as ap\n",
    "from src.utils import data_handler as dh\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model save path:\n",
    "inv_save_path = '/Users/francescomaraschin/Desktop/IntelligentVehicles/Project_NN_Conda/data/trained_models/inverse_model/inverse_model.h5'\n",
    "\n",
    "inverse_model = tf.keras.models.load_model(filepath=inv_save_path,\n",
    "                                            custom_objects={\n",
    "                                                'MyInitializer': ci.MyInitializer,\n",
    "                                                'ActivLin1D': ActivLin1D\n",
    "                                            })\n",
    "\n",
    "# Reshape and split data\n",
    "inverse_dataset_path = '/Users/francescomaraschin/Desktop/IntelligentVehicles/LongitudinalControllerNN/Data/csv/inverse_dataset.csv'\n",
    "inverse_dataset = dh.load_csv(inverse_dataset_path)\n",
    "train_data, valid_data, time = dh.window_data(dataset=inverse_dataset,\n",
    "                                              input_labels=['acceleration',\n",
    "                                                            'velocity'],\n",
    "                                              output_labels=['pedal'],\n",
    "                                              input_window=10,\n",
    "                                              output_window=1,\n",
    "                                              batch_size=100,\n",
    "                                              validation_split=0.3)\n",
    "\n",
    "velocity = train_data[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activ_lin_1d(act_in, chan_id, chan_arr):\n",
    "    '''\n",
    "    Copy of the ActivLin1D class as Python function using numpy covering only the actual channels.\n",
    "\n",
    "    Arguments:\n",
    "     - act_in:   the input that activates the channels;\n",
    "     - chan_id:  index of the channel center (i.e., of the chan_arr element);\n",
    "     - chan_arr: array containing the channel centers.\n",
    "\n",
    "    Outputs:\n",
    "     - act_fcn: the activation function.\n",
    "    '''\n",
    "\n",
    "    # Compute the number of channels\n",
    "    chan_num = len(chan_arr)\n",
    "\n",
    "    # First dimension of activation\n",
    "    if chan_id == 0:\n",
    "        if chan_num != 1:\n",
    "            ampl    = chan_arr[1] - chan_arr[0]\n",
    "            act_fcn = np.minimum(\n",
    "                np.maximum(-(act_in - chan_arr[0])/ampl + 1, 0), 1)\n",
    "\n",
    "        else:\n",
    "            act_fcn = 1 # in case the user only wants one channel\n",
    "\n",
    "    elif chan_id != 0 and chan_id == (chan_num - 1):\n",
    "        ampl    = chan_arr[-1] - chan_arr[-2]\n",
    "        act_fcn = np.minimum(\n",
    "            np.maximum((act_in - chan_arr[-2])/ampl, 0), 1)\n",
    "\n",
    "    else:\n",
    "        ampl_1  = chan_arr[chan_id] - chan_arr[chan_id - 1]\n",
    "        ampl_2  = chan_arr[chan_id + 1] - chan_arr[chan_id]\n",
    "        act_fcn = np.minimum(\n",
    "            np.maximum((act_in - chan_arr[chan_id - 1])/ampl_1, 0),\n",
    "            np.maximum(-(act_in - chan_arr[chan_id])/ampl_2 + 1, 0))\n",
    "\n",
    "    return act_fcn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chan = 10\n",
    "chan_arr = np.array([-1.0,\n",
    "        -0.8114791181352403,\n",
    "        -0.6229582362704806,\n",
    "        -0.43443735440572107,\n",
    "        -0.24591647254096138,\n",
    "        -0.0573955906762017,\n",
    "        0.13112529118855787,\n",
    "        0.31964617305331755,\n",
    "        0.5081670549180772,\n",
    "        0.6966879367828369\n",
    "                     ])\n",
    "\n",
    "act_in = velocity\n",
    "\n",
    "act_fcn  = np.array([activ_lin_1d(act_in=act_in,\n",
    "                                  chan_id=i,\n",
    "                                  chan_arr=chan_arr) for i in range(num_chan)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695548</td>\n",
       "      <td>0.304452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695548</td>\n",
       "      <td>0.304452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695548</td>\n",
       "      <td>0.304452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695550</td>\n",
       "      <td>0.304450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695582</td>\n",
       "      <td>0.304418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11196</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11198</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11199</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11200 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4         5         6    7    8    9\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.695548  0.304452  0.0  0.0  0.0\n",
       "1      0.0  0.0  0.0  0.0  0.0  0.695548  0.304452  0.0  0.0  0.0\n",
       "2      0.0  0.0  0.0  0.0  0.0  0.695548  0.304452  0.0  0.0  0.0\n",
       "3      0.0  0.0  0.0  0.0  0.0  0.695550  0.304450  0.0  0.0  0.0\n",
       "4      0.0  0.0  0.0  0.0  0.0  0.695582  0.304418  0.0  0.0  0.0\n",
       "...    ...  ...  ...  ...  ...       ...       ...  ...  ...  ...\n",
       "11195  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  1.0\n",
       "11196  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  1.0\n",
       "11197  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  1.0\n",
       "11198  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  1.0\n",
       "11199  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  1.0\n",
       "\n",
       "[11200 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(act_fcn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the result\n",
    "plt.figure()\n",
    "plt.plot(act_in, act_fcn)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_sum =  np.mean(np.sum(act_fcn, axis=1))\n",
    "assert check_sum == 1.0,\\\n",
    "           f'The sum of all activation functions is not 1, it is: {check_sum:.4e}'\n",
    "print(f'The sum of all activation functions is: {check_sum:.4e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
